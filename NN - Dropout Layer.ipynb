{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1edfc01a",
   "metadata": {},
   "source": [
    "# NN - Dropout Layer\n",
    "\n",
    "\n",
    "* Dropout is an approach to regularization in neural networks which help in independent learning of the neurons.\n",
    "\n",
    "* Dropout means removing of neurons at random in a hidden layer to avoid overfitting.\n",
    "\n",
    "* We have many neurons which develop codependency among each other during the training of the neural network, which curbs their individual power.\n",
    "\n",
    "    * The learning efficiency becomes weak, and thus can produce overfitting.\n",
    "    \n",
    "* Regularization reduces overfitting, by adding penalty to all features which are useless.\n",
    "\n",
    "# Common Observations\n",
    "\n",
    "1. Dropout forces the neural network to learn more robust features that are useful for predictive analytics.\n",
    "\n",
    "2. Dropout helps us to reduce the training time required for the neural network.\n",
    "\n",
    "3. Choosing the right value for the dropout is crucial to get good results.\n",
    "\n",
    "\n",
    "### Values for Dropout\n",
    "\n",
    "* Values for Dropout vary from 0 to 1.\n",
    "\n",
    "* If 0 is specified it means no dropout is required.\n",
    "\n",
    "* 0.2 means 20% of all the neurons from hidden layer are removed.\n",
    "\n",
    "* 0.5 means 50% of all the neurons from the specified hidden layer are removed at random.\n",
    "\n",
    "\n",
    "### Optimal Value for Dropout\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
