{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01362f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"\"\"I'm amazed how often in practice, not only does a @huggingface NLP model solve your problem, but one of their public finetuned checkpoints, is good enough for the job.\\n\\n\n",
    "Both impressed, and a little disappointed how rarely I get to actually train a model that matters :(\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6894ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm\",\n",
       " 'amazed',\n",
       " 'how',\n",
       " 'often',\n",
       " 'in',\n",
       " 'practice,',\n",
       " 'not',\n",
       " 'only',\n",
       " 'does',\n",
       " 'a',\n",
       " '@huggingface',\n",
       " 'NLP',\n",
       " 'model',\n",
       " 'solve',\n",
       " 'your',\n",
       " 'problem,',\n",
       " 'but',\n",
       " 'one',\n",
       " 'of',\n",
       " 'their',\n",
       " 'public',\n",
       " 'finetuned',\n",
       " 'checkpoints,',\n",
       " 'is',\n",
       " 'good',\n",
       " 'enough',\n",
       " 'for',\n",
       " 'the',\n",
       " 'job.',\n",
       " 'Both',\n",
       " 'impressed,',\n",
       " 'and',\n",
       " 'a',\n",
       " 'little',\n",
       " 'disappointed',\n",
       " 'how',\n",
       " 'rarely',\n",
       " 'I',\n",
       " 'get',\n",
       " 'to',\n",
       " 'actually',\n",
       " 'train',\n",
       " 'a',\n",
       " 'model',\n",
       " 'that',\n",
       " 'matters',\n",
       " ':(']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269302b",
   "metadata": {},
   "source": [
    "#### \"amaz\" + \"--ing\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f32e5f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'\",\n",
       " 'm',\n",
       " ' ',\n",
       " 'a',\n",
       " 'm',\n",
       " 'a',\n",
       " 'z',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'i',\n",
       " 'c',\n",
       " 'e',\n",
       " ',',\n",
       " ' ',\n",
       " 'n',\n",
       " 'o',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " 'e',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " '@',\n",
       " 'h',\n",
       " 'u',\n",
       " 'g',\n",
       " 'g',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " 'f',\n",
       " 'a',\n",
       " 'c',\n",
       " 'e',\n",
       " ' ',\n",
       " 'N',\n",
       " 'L',\n",
       " 'P',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'l',\n",
       " 'v',\n",
       " 'e',\n",
       " ' ',\n",
       " 'y',\n",
       " 'o',\n",
       " 'u',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'r',\n",
       " 'o',\n",
       " 'b',\n",
       " 'l',\n",
       " 'e',\n",
       " 'm',\n",
       " ',',\n",
       " ' ',\n",
       " 'b',\n",
       " 'u',\n",
       " 't',\n",
       " ' ',\n",
       " 'o',\n",
       " 'n',\n",
       " 'e',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " 'i',\n",
       " 'r',\n",
       " ' ',\n",
       " 'p',\n",
       " 'u',\n",
       " 'b',\n",
       " 'l',\n",
       " 'i',\n",
       " 'c',\n",
       " ' ',\n",
       " 'f',\n",
       " 'i',\n",
       " 'n',\n",
       " 'e',\n",
       " 't',\n",
       " 'u',\n",
       " 'n',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'c',\n",
       " 'h',\n",
       " 'e',\n",
       " 'c',\n",
       " 'k',\n",
       " 'p',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 's',\n",
       " ',',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'g',\n",
       " 'o',\n",
       " 'o',\n",
       " 'd',\n",
       " ' ',\n",
       " 'e',\n",
       " 'n',\n",
       " 'o',\n",
       " 'u',\n",
       " 'g',\n",
       " 'h',\n",
       " ' ',\n",
       " 'f',\n",
       " 'o',\n",
       " 'r',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 'j',\n",
       " 'o',\n",
       " 'b',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'B',\n",
       " 'o',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 'i',\n",
       " 'm',\n",
       " 'p',\n",
       " 'r',\n",
       " 'e',\n",
       " 's',\n",
       " 's',\n",
       " 'e',\n",
       " 'd',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " 'n',\n",
       " 'd',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'l',\n",
       " 'i',\n",
       " 't',\n",
       " 't',\n",
       " 'l',\n",
       " 'e',\n",
       " ' ',\n",
       " 'd',\n",
       " 'i',\n",
       " 's',\n",
       " 'a',\n",
       " 'p',\n",
       " 'p',\n",
       " 'o',\n",
       " 'i',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'd',\n",
       " ' ',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 'r',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'g',\n",
       " 'e',\n",
       " 't',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'a',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'a',\n",
       " 'l',\n",
       " 'l',\n",
       " 'y',\n",
       " ' ',\n",
       " 't',\n",
       " 'r',\n",
       " 'a',\n",
       " 'i',\n",
       " 'n',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'm',\n",
       " 'o',\n",
       " 'd',\n",
       " 'e',\n",
       " 'l',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'a',\n",
       " 't',\n",
       " ' ',\n",
       " 'm',\n",
       " 'a',\n",
       " 't',\n",
       " 't',\n",
       " 'e',\n",
       " 'r',\n",
       " 's',\n",
       " ' ',\n",
       " ':',\n",
       " '(']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for char in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b26a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@elonmusk thinks that the NLP models that @joebloggs made are super cool\\n<USER> thinks that the NLP models that <USER> made are super cool\\n\\n<URL>\\n<MONETARY>\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@elonmusk thinks that the NLP models that @joebloggs made are super cool\n",
    "<USER> thinks that the NLP models that <USER> made are super cool\n",
    "\n",
    "<URL>\n",
    "<MONETARY>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d82c566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '[UNK]',\n",
       " 'thinks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'that',\n",
       " '[UNK]',\n",
       " 'made',\n",
       " 'are',\n",
       " 'super',\n",
       " 'cool',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Special Model Tokens\n",
    "\n",
    "\"\"\"\n",
    "token:                                   Meaning:\n",
    "-----                                    -----\n",
    "[PAD] Padding token, allows us to maintain same-length sequences (512 tokens for Bert) even when different sized sentences are fed in\n",
    "[UNK] Used when a word is unknown to Bert\n",
    "[CLS] Appears at the start of every sequence\n",
    "[SEP] Indicates a seperator or end of sequence\n",
    "[MASK] Used when masking tokens, for example in training with Masked Language Modelling (MLM)\n",
    "\"\"\"\n",
    "\n",
    "\"[CLS] [UNK] thinks that the NLP models that [UNK] made are super cool [SEP] [PAD] [PAD]\".split()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
