{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc0b242",
   "metadata": {},
   "source": [
    "# SENTIMENT ANALYZER ENGINE (MODEL)\n",
    "\n",
    "You need a developer account and a registered App on Twitter for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07acb56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy, re\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9c97b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter authentication with tweepy\n",
    "\n",
    "consumerKey = ''\n",
    "consumerSecret = ''\n",
    "accessToken = ''\n",
    "accessTokenSecret = ''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumerkey, consumerSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for term to be searched and how many tweets to search\n",
    "\n",
    "searchTerm = input(\"Enter Keyword/Tag to search: \")\n",
    "NoOfTerms = int(input(\"How many tweets to search: \"))\n",
    "\n",
    "tweets = []\n",
    "tweetText = []\n",
    "\n",
    "# searching for tweets\n",
    "tweets = tweepy.Cursor(api.search, q=searchTerm+\" -filter:retweets\", lang=\"en\").items(NoOfTerms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b95106",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = [tweet.text for tweet in tweets]\n",
    "tweet_df = pd.DataFrame(tweet_list)\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ee4b8",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecff9894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    return ' '.join(re.sub(\"(@[a-zA-Z0-9]+)|([^0-9A-Za-z])|(https://[\\w.]+[\\w]+)\", \" \", text).split())\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df[0].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_numbers(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d', i):\n",
    "            list_text_new.append(i)\n",
    "    return ''.join(list_text_new)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(drop_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184138ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810d0618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(text):\n",
    "    text_words = word_tokenize(text)\n",
    "    text_words_lower = [x.lower() for x in text_words]\n",
    "    return ' '.join(text_words_lower)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48170eb",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "#### FIRST DOWNLOAD THE \"WORDNET\" PACKAGE FROM \"NLTK LIBRARY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf1f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatise(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    text_lemm = [lemmatizer.lemmatize(word) for word in text_tokens]\n",
    "    return ' '.join(text_lemm)\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(lemmatise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac3676",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['cleaned_data'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b91eb",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d58a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    text_tokens = word_tokenize(text)\n",
    "    tokens = [word for word in text_tokens if not word in set(stopwords.words('english'))]\n",
    "    tokens_text = ' '.join(tokens)\n",
    "    return tokens_text\n",
    "\n",
    "tweet_df['cleaned_data'] = tweet_df['cleaned_data'].apply(remove_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['cleaned_data'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd0767",
   "metadata": {},
   "source": [
    "# Sentiment Analyzer Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the polarity\n",
    "# Polarity determines the sentimental aspect of an opinion from -1 to +1,\n",
    "# where 0 is neutral sentiment\n",
    "\n",
    "def get_polarity(text):\n",
    "    textblob = TextBlob(str(text))\n",
    "    pol = textblob.sentiment.polarity\n",
    "    if (pol == 0):\n",
    "        return \"Neutral\"\n",
    "    elif (pol>0 and pol <=0.3):\n",
    "        return \"Weakly Positive\"\n",
    "    elif (pol>0.3 and pol <=0.6):\n",
    "        return \"Positive\"\n",
    "    elif (pol>0.6 and pol<=1):\n",
    "        return \"Strongly Positive\"\n",
    "    elif (pol>-0.3 and pol<=0):\n",
    "        return \"Weakly Negative\"\n",
    "    elif (pol>-0.6 and pol<=-0.3):\n",
    "        return \"Negative\"\n",
    "    elif (pol>-1 and pol<=-0.6):\n",
    "        return \"Strongly Negative\"\n",
    "    \n",
    "tweet_df['polarity'] = tweet_df['cleaned_data'].apply(get_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd42263",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07226647",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral = 0\n",
    "wpositive = 0\n",
    "spositive = 0\n",
    "positive = 0\n",
    "negative = 0\n",
    "wnegative = 0\n",
    "snegative = 0\n",
    "polarity = 0\n",
    "\n",
    "for i in range(0,70):\n",
    "    textblob = TextBlob(str(tweet_df['cleaned_data'][i]))\n",
    "    polarity += textblob.sentiment.polarity\n",
    "    pol = textblob.sentiment.polarity\n",
    "    if (pol==0): #adding reaction of how people are reacting to find\n",
    "        neutral += 1\n",
    "    elif (pol>0 and pol<=0.3):\n",
    "        wpositive += 1\n",
    "    elif (pol>0.3 and pol<=0.6):\n",
    "        positive += 1\n",
    "    elif (pol>0.6 and pol<1):\n",
    "        spositive +=1\n",
    "    elif (pol>-0.3 and pol<=0):\n",
    "        wnegative += 1\n",
    "    elif (pol>-0.6 and pol<=-0.3):\n",
    "        negative += 1\n",
    "    elif (pol>-1 and pol<=-0.6):\n",
    "        snegative += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc894b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find average reaction\n",
    "\n",
    "polarity = polarity / noOfTerms\n",
    "polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50b7a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part, whole):\n",
    "    temp = 100 * float(part) / float(whole)\n",
    "    return format(temp, '.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56dfa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding average of how people are reacting\n",
    "positive = percentage(positive, NoOfTerms)\n",
    "wpositive = percentage(wpositive, NoOfTerms)\n",
    "spositive = percentage(spositive, NoOfTerms)\n",
    "negative = percentage(negative, NoOfTerms)\n",
    "wnegative = percentage(wnegative, NoOfTerms)\n",
    "snegative = percentage(snegative, NoOfTerms)\n",
    "neutral = percentage(neutral, NoOfTerms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0a310a",
   "metadata": {},
   "source": [
    "# Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing data\n",
    "\n",
    "print(\"How people are reacting on \" + searchTerm + \" by analyzing \" + str(NoOfTerms) + \" tweets.\")\n",
    "print()\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"General Report: \")\n",
    "\n",
    "if (polarity == 0):\n",
    "    print(\"Neutral\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Weakly Positive\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Positive\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Strongly Positive\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Weakly Negative\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Negative\")\n",
    "elif (polarity > 0 and polarity <= 0.3):\n",
    "    print(\"Strongly Positive\")\n",
    "    \n",
    "print()\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Detailed Report: \")\n",
    "print(str(positive) + \"% people thought it was positive\")\n",
    "print(str(wpositive) + \"% people thought it was weakly positive\")\n",
    "print(str(spositive) + \"% people thought it was strongly positive\")\n",
    "print(str(negative) + \"% people thought it was negaive\")\n",
    "print(str(wnegative) + \"% people thought it was weakly negative\")\n",
    "print(str(snegative) + \"% people thought it was strongly negative\")\n",
    "print(str(neutral) + \"% people thought it was neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb892a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizer = [positive, wpositive, spositive, neutral, negative, wnegative, snegative]\n",
    "colors = ['yellowgreen', 'lightgreen', 'darkgreen', 'gold', 'red', 'lightsalmon', 'darkred']\n",
    "labels = ['Positive [' + str(positive) + '%]', 'Weakly Positive [' + str(wpositive) + '%]',\n",
    "          'Strongly Positive [' + str(spositive) + '%]', 'Neutral [' + str(neutral) + '%]',\n",
    "          'Negative [' + str(negative) + '%]', 'Weakly Negative [' + str(wnegative) + '%]',\n",
    "          'Strongly Negative [' + str(snegative) + '%]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac314c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(sizes, labels = labels, colors = colors)\n",
    "plt.legend(labels, loc=\"best\")\n",
    "plt.title('How people are reacting to ' + searchTerm + ' by analyzing ' + str(NoOfTerms) + ' Tweets.')\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
