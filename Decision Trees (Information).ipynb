{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83031dca",
   "metadata": {},
   "source": [
    "# Decision Trees (Information)\n",
    "\n",
    "\n",
    "### Information\n",
    "\n",
    "1. We can consider Decision Tree like a bunch of nested if-statements.\n",
    "\n",
    "2. Spam.\n",
    "    a. Earn free money by playing a game.\n",
    "    b. Free money!!!! sign up here.\n",
    "    \n",
    "3. Not Spam.\n",
    "    a. Hi good morning, could we get on a quick call? I have a few doubts!\n",
    "    \n",
    "    \n",
    "### Example\n",
    "\n",
    "if 'money' in mail:\n",
    "    if 'free' in mail:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "return False\n",
    "\n",
    "              - Money -\n",
    "            Yes        No  \n",
    "         - Free -     Not spam\n",
    "       Yes       No\n",
    "      Spam      Not spam\n",
    "      \n",
    "      \n",
    "### Geometry\n",
    "\n",
    "* x,y distribution.\n",
    "    * Here we have to predict the health of a person based on the height and weights.\n",
    "    * Split on Weight = 80, and height = 4\n",
    "    \n",
    "1. With more numbers of features and splits the results can be highly non lineaer i.e., it will be able to fit the complex patterns much better than the linear models.\n",
    "\n",
    "2. A bunch of 'if' statements doesn't sound like machine learning\n",
    "    a. what makes it machine learning is how we choose the condition on which we want to split - Information theory.\n",
    "    \n",
    "    \n",
    "# Advantages and issues w/ Decision Trees\n",
    "\n",
    "\n",
    "### Advantages\n",
    "\n",
    "1. Visualization, simple if-else statements can be understood by evveryone.\n",
    "2. Can solve classification and regression problems.\n",
    "3. Efficiently handle both continuous and categorical variables with very less preprocessing involved.\n",
    "4. Decision Trees use rulebased approach. We don't need to use any feature scaling methods like standardization and normalization.\n",
    "5. Compared to other models Decision Trees are very good in handling missing values.\n",
    "6. If there is a high nonlinear pattern between independent variables, Decision Trees will outperform in comparison to all the linear models.\n",
    "\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "1. A decision tree grown up to an arbitrary depth will always overfit.\n",
    "    a. If we let the decision tree grow up to large depth it would surely find a way to classify the datapoint in a leaf node of some branch which might not be a generalized solution.\n",
    "    \n",
    "2. Decision trees are highly unstable, adding a new data point can lead to re-generation of the overall tree and all nodes need to be recalculated and recreated.\n",
    "\n",
    "3. If data size is large, then one single tree may grow complex and lead to overfitting. In this case we use ensemble models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
