{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e8602d",
   "metadata": {},
   "source": [
    "# Support Vector Machines & Hyperplane\n",
    "\n",
    "\n",
    "### SVM Information\n",
    "\n",
    "* It can be used for both valuary or multi-class classification.\n",
    "\n",
    "* Can be used for both classification or regression challenges.\n",
    "\n",
    "* Mostly used in classification problems.\n",
    "\n",
    "* It's very good when we have a huge number of features.\n",
    "\n",
    "* SVMs can efficiently perform a non-linear classification using implicit mapping the inputs into high-dimensional feature spaces.\n",
    "\n",
    "* A hard margin means that an SVM is very rigid in classification and tries to work extremely well in the training set. It allows very low errors in classification. Thus can be susceptible to overfitting.\n",
    "\n",
    "* The effectiveness of an SVM depends upon:\n",
    "\n",
    "    a. Selection of Kernel\n",
    "    b. Kernel parameters\n",
    "    c. Soft margin parameters C\n",
    "    \n",
    "* The SVM's are less effective when the data is noisy and contains overlapping points.\n",
    "\n",
    "* RBF kernel in SVM with high Gamma value would consider only the points close to the hyperplane for modelling.\n",
    "\n",
    "\n",
    "### Support Vector Machines\n",
    "\n",
    "* Support Vector Machines or SVMs are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis.\n",
    "\n",
    "* SVM is a generalization of a classifier called maximum margin classifier.\n",
    "\n",
    "* Maximum Margin Classifier can't be used in a lot of scenarios.\n",
    "\n",
    "* That is why the support vector classifier was introduced as an extension of the maximum margin classifier, which can be applied in a broader range of cases.\n",
    "\n",
    "* A support vector machine is simple a further extension of the support vector classifier to accomodate non linear class boundaries.\n",
    "\n",
    "* It can be used on both binary or multiclass classification\n",
    "\n",
    "* SVMs are non-probabilistic, so they assign a data point to a class with 100% certainty.\n",
    "\n",
    "* Two SVMs giving the same class assignment to a set of data points have the same classification accuracy.\n",
    "\n",
    "* If 2 SVMs give the same class assignment of data points the model will choose the data point furthest away from its classification boundary.\n",
    "\n",
    "* Ideally the classification boundary will be a curve that goes right in the middle of the gap between classes, because this would be the classification boundary with the largest distance to the closest data point.\n",
    "\n",
    "* In the case of 2 lineary seperable boundaries in the plane, this boundary would be a line that passes through the middle of the 2 data points of different classes.\n",
    "\n",
    "\n",
    "### Hyperplane\n",
    "\n",
    "* Boundary would be a line that passes through the middle of the 2 closest data points from different classes.\n",
    "\n",
    "* Passign through the midpoint of the line connecting two data points maximizes the distance to each data point. In more than two dimensions, this boundary is known as a hyperplane.\n",
    "\n",
    "* data points falling on either side of the hyperplane can be attributes to different classes.\n",
    "\n",
    "B0 + B1X1 + B2X2 + ... + BpXp = 0\n",
    "\n",
    "* If X satisfies the equation above, then the point lies on the plane. Otherwise, it must be on side of the plane.\n",
    "\n",
    "* We calculate the perpendicular distance from each training observication given a hyperplane.\n",
    "\n",
    "* This is known as the margin, hence the optimum separating hyperplane is the one with the largest margin.\n",
    "\n",
    "* Points with an equal distance to the boundary are called support vectors. Because if their position shifts the hyperplane shifts as well.\n",
    "\n",
    "* The hyperplane depends consistently only on the support vectors and not any other observations.\n",
    "\n",
    "\n",
    "### If no Separating Plane exists\n",
    "\n",
    "* If there is no maximal margin classifier, we use a support vector classifier that can almost separate the classes using a soft margin called support vector classifier.\n",
    "\n",
    "* SVM is an extension of the support vector classifier that result from enlarging the features using kernels.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
