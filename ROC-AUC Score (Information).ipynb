{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ab0f8",
   "metadata": {},
   "source": [
    "# USING ROC-AUC SCORE TO ANALYZE MODEL PERFORMANCE\n",
    "\n",
    "#### Threshold\n",
    "\n",
    "1. you can move your threshold up or down based on the requirement.\n",
    "\n",
    "2. If we're doing a disease prediction, we have to be very sure when we predict that the person doesn't have a disease [label 0]\n",
    "\n",
    "    a. we can move our threshold closer to \"0\" making the range of predictin zero less\n",
    "    \n",
    "3. If we're trying to predict a spam email, we have to be very confident when we predict that the email is spam [label 1]\n",
    "    \n",
    "    a. we move our threshold closer to \"1\" making the range of predicting 1 tight\n",
    "\n",
    "\n",
    "* With a threshold of 0.7, we would have predicted the logit score of 0.6 and 0 correct, and prediction would correctly be 0 in the case of True label (Y) = 0\n",
    "\n",
    "True label (Y)   Logit [sig(w.x + c)]    threshold    prediction\n",
    "1                0.9                     0.5          1\n",
    "1                0.82                    0.5          1\n",
    "0                0.6                     0.5          1\n",
    "1                0.75                    0.5          1\n",
    "\n",
    "\n",
    "TN=0    FP=1\n",
    "FN=0    TP=3\n",
    "\n",
    "\n",
    "#### ROC - RECEIVER OPERATOR CHARACTERISTIC\n",
    "\n",
    "1. ROC provides a simple way to summarize all the information.\n",
    "2. Y - True positive rate.\n",
    "3. X - False positive rate.\n",
    "\n",
    "\n",
    "#### Steps for calculating ROC\n",
    "\n",
    "1. Start from a very low thresholde i.e.., 0.01.\n",
    "\n",
    "2. Compute predictions and calculate the confusion matrix.\n",
    "\n",
    "3. Calculate \"True positive rate\", \"False positive rate\" and collect them for visualization purpose.\n",
    "\n",
    "4. Iterate [1,2,3] by increasing threshold by 0.01 until we reach the maximum threshold 0.99.\n",
    "\n",
    "5. Connect all the dots and we see a graph, this is called the ROC graph.\n",
    "\n",
    "\n",
    "#### AUC - AREA UNDER THE CURVE\n",
    "\n",
    "1. Total area the \"ROC\" graph has covered.\n",
    "\n",
    "2. Comparison metric to select the best model out of all the trained models.\n",
    "\n",
    "3. Suppose we have trained two logistic regression models with different hyper parameters and we are confused when selecting the best one out of both.\n",
    "\n",
    "    a. plot the \"ROC\" for the two models and calculate the \"AUC\" of each graph.\n",
    "    b. select the model that has a higher \"AUC\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
